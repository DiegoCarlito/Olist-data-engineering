{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63743a9",
   "metadata": {},
   "source": [
    "# Pipeline ETL: Camada Prata para Ouro\n",
    "\n",
    "## 1. Objetivo\n",
    "\n",
    "Este notebook é responsável pela construção do Data Warehouse (Camada Gold). O processo consiste em:\n",
    "1.  **Extrair** os dados denormalizados da tabela `orders` (Camada Silver).\n",
    "2.  **Transformar** os dados aplicando a modelagem dimensional (Star Schema), separando os atributos em tabelas Dimensão e as métricas em uma tabela Fato.\n",
    "3.  **Carregar** os dados no schema `dw` do PostgreSQL, gerando chaves substitutas (Surrogate Keys) para garantir a integridade referencial e performance de BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETLSilverToGoldOlist\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.5.0\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 1000) \\\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"SparkSession iniciada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8ed41",
   "metadata": {},
   "source": [
    "## 2. Preparação do Ambiente (Schema DW)\n",
    "\n",
    "Antes de iniciar a carga, executamos o script DDL (`gold_ddl.sql`) para garantir que o schema `dw` e as tabelas de destino (`dim_...` e `ft_...`) existam e estejam limpas (reset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7104d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando DDL...\n",
      "Schema DW recriado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "def carregar_env():\n",
    "    env_path = '../../.env'\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "    return {\n",
    "        \"user\": os.getenv(\"DB_USER\"),\n",
    "        \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "        \"host\": os.getenv(\"DB_HOST\"),\n",
    "        \"port\": os.getenv(\"DB_PORT\"),\n",
    "        \"dbname\": os.getenv(\"DB_NAME\")\n",
    "    }\n",
    "\n",
    "def resetar_dw(env_vars):\n",
    "    ddl_path = \"../../DataLayer/gold/gold_ddl.sql\"\n",
    "    print(\"Executando DDL...\")\n",
    "    try:\n",
    "        conn = psycopg2.connect(**env_vars)\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "        with open(ddl_path, 'r') as f:\n",
    "            cur.execute(f.read())\n",
    "        print(\"Schema DW recriado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no DDL: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if 'cur' in locals(): cur.close()\n",
    "        if 'conn' in locals(): conn.close()\n",
    "\n",
    "env_vars = carregar_env()\n",
    "resetar_dw(env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395af1da",
   "metadata": {},
   "source": [
    "## 3. Extração (Leitura da Silver)\n",
    "\n",
    "Lemos os dados da \"Tabelona\" (`public.orders`) diretamente do PostgreSQL para um DataFrame Spark. Esta é a nossa fonte única da verdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo dados da camada Silver...\n",
      "Linhas carregadas: 88981\n"
     ]
    }
   ],
   "source": [
    "jdbc_url = f\"jdbc:postgresql://{env_vars['host']}:{env_vars['port']}/{env_vars['dbname']}\"\n",
    "jdbc_props = {\"user\": env_vars['user'], \"password\": env_vars['password'], \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "print(\"Lendo dados da camada Silver...\")\n",
    "df_silver = spark.read.jdbc(jdbc_url, \"public.orders\", properties=jdbc_props)\n",
    "df_silver.cache()\n",
    "print(f\"Linhas carregadas: {df_silver.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7658ea",
   "metadata": {},
   "source": [
    "## 4. Processamento das Dimensões (Transform & Load)\n",
    "\n",
    "Nesta etapa, \"fatiamos\" os dados da Silver para criar as tabelas de dimensão. Para cada dimensão:\n",
    "1.  Selecionamos colunas distintas.\n",
    "2.  Geramos uma Surrogate Key (`sk_`) sequencial.\n",
    "3.  Carregamos na tabela correspondente no PostgreSQL (`dw.dim_...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34bb64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Dimensões (Cliente, Vendedor, Produto, Pagamento)...\n",
      "Carregando Dimensões no PostgreSQL...\n",
      "Carga de Dimensões concluída.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processando Dimensões (Cliente, Vendedor, Produto, Pagamento)...\")\n",
    "\n",
    "dim_cliente = df_silver.select(\n",
    "    F.col(\"customer_unique_id\").alias(\"nk_id_cliente\"),\n",
    "    F.col(\"customer_city\").alias(\"nm_cidade\"),\n",
    "    F.col(\"customer_state\").alias(\"sg_estado\")\n",
    ").distinct()\n",
    "dim_cliente = dim_cliente.withColumn(\"sk_cliente\", F.row_number().over(Window.orderBy(\"nk_id_cliente\")))\n",
    "\n",
    "dim_vendedor = df_silver.select(\n",
    "    F.col(\"seller_id\").alias(\"nk_id_vendedor\"),\n",
    "    F.col(\"seller_city\").alias(\"nm_cidade\"),\n",
    "    F.col(\"seller_state\").alias(\"sg_estado\")\n",
    ").distinct()\n",
    "dim_vendedor = dim_vendedor.withColumn(\"sk_vendedor\", F.row_number().over(Window.orderBy(\"nk_id_vendedor\")))\n",
    "\n",
    "dim_produto = df_silver.select(\n",
    "    F.col(\"product_id\").alias(\"nk_id_produto\"),\n",
    "    F.col(\"product_category_name\").alias(\"nm_categoria\")\n",
    ").distinct()\n",
    "dim_produto = dim_produto.withColumn(\"sk_produto\", F.row_number().over(Window.orderBy(\"nk_id_produto\")))\n",
    "\n",
    "dim_pagamento = df_silver.select(\n",
    "    F.col(\"payment_type\").alias(\"ds_tipo_pagamento\"),\n",
    "    F.col(\"payment_installments\").alias(\"nr_parcelas\")\n",
    ").distinct()\n",
    "dim_pagamento = dim_pagamento.withColumn(\"sk_pagamento\", F.row_number().over(Window.orderBy(\"ds_tipo_pagamento\", \"nr_parcelas\")))\n",
    "\n",
    "print(\"Carregando Dimensões no PostgreSQL...\")\n",
    "dim_cliente.select(\"nk_id_cliente\", \"nm_cidade\", \"sg_estado\").write.jdbc(jdbc_url, \"dw.dim_cliente\", \"append\", jdbc_props)\n",
    "dim_vendedor.select(\"nk_id_vendedor\", \"nm_cidade\", \"sg_estado\").write.jdbc(jdbc_url, \"dw.dim_vendedor\", \"append\", jdbc_props)\n",
    "dim_produto.select(\"nk_id_produto\", \"nm_categoria\").write.jdbc(jdbc_url, \"dw.dim_produto\", \"append\", jdbc_props)\n",
    "dim_pagamento.select(\"ds_tipo_pagamento\", \"nr_parcelas\").write.jdbc(jdbc_url, \"dw.dim_pagamento\", \"append\", jdbc_props)\n",
    "print(\"Carga de Dimensões concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31113e73",
   "metadata": {},
   "source": [
    "### 4.1. Dimensão Tempo\n",
    "\n",
    "A Dimensão Tempo é gerada a partir das datas de compra existentes. Enriquecemos os dados extraindo atributos como Dia, Mês, Ano, Trimestre, Semestre e Flag de Fim de Semana para facilitar a análise temporal no dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1defa81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Dimensão Tempo...\n",
      "Dimensão Tempo carregada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processando Dimensão Tempo...\")\n",
    "\n",
    "df_datas = df_silver.select(F.to_date(\"order_purchase_timestamp\").alias(\"data_completa\")).distinct()\n",
    "\n",
    "dim_tempo = df_datas.select(\n",
    "    F.col(\"data_completa\"),\n",
    "    F.date_format(\"data_completa\", \"yyyyMMdd\").cast(\"int\").alias(\"sk_tempo\"),\n",
    "    F.year(\"data_completa\").alias(\"nr_ano\"),\n",
    "    F.month(\"data_completa\").alias(\"nr_mes\"),\n",
    "    F.date_format(\"data_completa\", \"MMMM\").alias(\"nm_mes\"),\n",
    "    F.dayofmonth(\"data_completa\").alias(\"nr_dia\"),\n",
    "    F.quarter(\"data_completa\").alias(\"nr_trimestre\"),\n",
    "    F.date_format(\"data_completa\", \"EEEE\").alias(\"nm_dia_semana\"),\n",
    "    (F.dayofweek(\"data_completa\").isin([1, 7])).alias(\"fl_fim_de_semana\")\n",
    ")\n",
    "\n",
    "dim_tempo.write.jdbc(jdbc_url, \"dw.dim_tempo\", \"append\", jdbc_props)\n",
    "print(\"Dimensão Tempo carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83290cee",
   "metadata": {},
   "source": [
    "## 5. Processamento da Tabela Fato (Transform & Load)\n",
    "\n",
    "Esta é a etapa final de integração. Realizamos o **JOIN** da tabela Silver original com as novas Dimensões criadas para substituir as chaves naturais (IDs originais) pelas chaves artificiais (`sk_`) do DW.\n",
    "\n",
    "Selecionamos apenas as chaves estrangeiras e as métricas numéricas para compor a tabela `dw.ft_vendas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc29a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Tabela Fato Vendas...\n",
      "Carregando Fato Vendas...\n",
      "Carga da Camada Gold concluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processando Tabela Fato Vendas...\")\n",
    "\n",
    "df_fato_base = df_silver.withColumn(\"data_join\", F.to_date(\"order_purchase_timestamp\"))\n",
    "\n",
    "df_fato = df_fato_base \\\n",
    "    .join(dim_cliente, df_fato_base.customer_unique_id == dim_cliente.nk_id_cliente, \"left\") \\\n",
    "    .join(dim_vendedor, df_fato_base.seller_id == dim_vendedor.nk_id_vendedor, \"left\") \\\n",
    "    .join(dim_produto, df_fato_base.product_id == dim_produto.nk_id_produto, \"left\") \\\n",
    "    .join(dim_tempo, df_fato_base.data_join == dim_tempo.data_completa, \"left\") \\\n",
    "    .join(dim_pagamento, \n",
    "          (df_fato_base.payment_type == dim_pagamento.ds_tipo_pagamento) & \n",
    "          (df_fato_base.payment_installments == dim_pagamento.nr_parcelas), \"left\")\n",
    "\n",
    "ft_vendas = df_fato.select(\n",
    "    F.col(\"sk_cliente\"),\n",
    "    F.col(\"sk_vendedor\"),\n",
    "    F.col(\"sk_produto\"),\n",
    "    F.col(\"sk_tempo\"),\n",
    "    F.col(\"sk_pagamento\"),\n",
    "    F.col(\"order_id\").alias(\"nk_id_pedido\"),\n",
    "    (F.col(\"price\") + F.col(\"freight_value\")).alias(\"vlr_total\"),\n",
    "    F.col(\"freight_value\").alias(\"vlr_frete\"),\n",
    "    F.col(\"price\").alias(\"vlr_item\"),\n",
    "    F.col(\"delivery_days\").alias(\"qtd_dias_entrega\"),\n",
    "    F.col(\"review_score\").alias(\"nota_avaliacao\"),\n",
    "    F.col(\"is_delivery_late\").alias(\"fl_atraso\")\n",
    ")\n",
    "\n",
    "print(\"Carregando Fato Vendas...\")\n",
    "ft_vendas.write.jdbc(jdbc_url, \"dw.ft_vendas\", \"append\", jdbc_props)\n",
    "print(\"Carga da Camada Gold concluída com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597464f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
